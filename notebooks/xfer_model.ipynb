{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/home/ravenoak/Projects/github.com/ravenoak/card-identifier/data/images/dataset')\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_size = (img_height, img_width),\n",
    "img_channels = 3\n",
    "input_shape = (img_height, img_width, img_channels)\n",
    "batch_size = 32\n",
    "train_seed = 1312\n",
    "val_seed = 1312\n",
    "train_epochs = 10\n",
    "num_classes = 116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 12:46:26.768628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, img_channels), include_top=False, weights=\"imagenet\")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    brightness_range=(-0.3, 0.7),\n",
    "    channel_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58000 files belonging to 116 classes.\n",
      "Using 11600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#    data_dir,\n",
    "#    validation_split=0.2,\n",
    "#    subset=\"training\",\n",
    "#    seed=train_seed,\n",
    "#    image_size=(img_height, img_width),\n",
    "#    batch_size=batch_size)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: img_gen.flow_from_directory(\n",
    "        data_dir,\n",
    "        batch_size=batch_size,\n",
    "    ),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(\n",
    "            shape=(None, img_height, img_width, img_channels),\n",
    "            dtype=tf.int32),\n",
    "        tf.TensorSpec(\n",
    "            shape=(None, num_classes),\n",
    "            dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "#train_ds = train_ds.padded_batch(batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=val_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "#val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 8, 8, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 116)               148596    \n",
      "=================================================================\n",
      "Total params: 2,406,580\n",
      "Trainable params: 148,596\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([base_model,\n",
    "                             tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                             tf.keras.layers.Dropout(0.2),\n",
    "                             tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "                             ])\n",
    "base_learning_rate = 0.00001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Found 58000 images belonging to 116 classes.\n",
      "   1017/Unknown - 1370s 1s/step - loss: 5.0910 - accuracy: 0.0096"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=train_epochs,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(500)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
