{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/home/ravenoak/Projects/github.com/ravenoak/card-identifier/data/images/dataset')\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_size = (img_height, img_width),\n",
    "img_channels = 3\n",
    "input_shape = (img_height, img_width, img_channels)\n",
    "batch_size = 32\n",
    "train_seed = 1312\n",
    "val_seed = 1312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58000 files belonging to 116 classes.\n",
      "Using 46400 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 00:19:33.709708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:33.767450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:33.767804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:33.769038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:33.769347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:33.769674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:34.766307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:34.766648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:34.766946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-17 00:19:34.767226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2177 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=train_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58000 files belonging to 116 classes.\n",
      "Using 11600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=val_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    #ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "#train_ds = configure_for_performance(train_ds)\n",
    "#val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "#normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#image_batch, labels_batch = next(iter(normalized_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/load_data/images\n",
    "#model = tf.keras.Sequential([\n",
    "#  tf.keras.layers.Rescaling(1./255),\n",
    "#  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#  tf.keras.layers.MaxPooling2D(),\n",
    "#  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#  tf.keras.layers.MaxPooling2D(),\n",
    "#  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#  tf.keras.layers.MaxPooling2D(),\n",
    "#  tf.keras.layers.Flatten(),\n",
    "#  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#  tf.keras.layers.Dense(num_classes)\n",
    "#])\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/keras/classification\n",
    "#model = Sequential([\n",
    "#    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dense(num_classes),\n",
    "#])\n",
    "\n",
    "# https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "    \n",
    "])\n",
    "\n",
    "# Rando!\n",
    "#model = Sequential([\n",
    "#    tf.keras.layers.Rescaling(1./255),\n",
    "#    tf.keras.layers.Conv2D(32, 16, 1),\n",
    "#    tf.keras.layers.MaxPooling2D(),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dense(num_classes),\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravenoak/.local/share/virtualenvs/card-identifier-6A9f_i46/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.000001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FIXME: This, below here...\n",
    "#model.build()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravenoak/.local/share/virtualenvs/card-identifier-6A9f_i46/lib/python3.9/site-packages/keras/backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n",
      "2021-10-17 00:19:37.364613: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-17 00:19:38.420344: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2021-10-17 00:19:39.395253: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-10-17 00:19:39.396176: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-10-17 00:19:39.396198: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2021-10-17 00:19:39.396769: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-10-17 00:19:39.396817: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450/1450 [==============================] - 84s 55ms/step - loss: 9.5334 - accuracy: 0.0085 - val_loss: 4.7585 - val_accuracy: 0.0082\n",
      "Epoch 2/500\n",
      "1450/1450 [==============================] - 81s 56ms/step - loss: 4.8918 - accuracy: 0.0086 - val_loss: 4.7548 - val_accuracy: 0.0081\n",
      "Epoch 3/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7988 - accuracy: 0.0089 - val_loss: 4.7541 - val_accuracy: 0.0080\n",
      "Epoch 4/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7745 - accuracy: 0.0089 - val_loss: 4.7540 - val_accuracy: 0.0080\n",
      "Epoch 5/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7656 - accuracy: 0.0089 - val_loss: 4.7539 - val_accuracy: 0.0080\n",
      "Epoch 6/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7606 - accuracy: 0.0085 - val_loss: 4.7537 - val_accuracy: 0.0080\n",
      "Epoch 7/500\n",
      "1450/1450 [==============================] - 81s 56ms/step - loss: 4.7582 - accuracy: 0.0078 - val_loss: 4.7536 - val_accuracy: 0.0077\n",
      "Epoch 8/500\n",
      "1450/1450 [==============================] - 79s 55ms/step - loss: 4.7561 - accuracy: 0.0082 - val_loss: 4.7536 - val_accuracy: 0.0077\n",
      "Epoch 9/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7563 - accuracy: 0.0087 - val_loss: 4.7536 - val_accuracy: 0.0070\n",
      "Epoch 10/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7555 - accuracy: 0.0088 - val_loss: 4.7536 - val_accuracy: 0.0070\n",
      "Epoch 11/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7546 - accuracy: 0.0089 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 12/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7550 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 13/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7547 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 14/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7542 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 15/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7543 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 16/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7535 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 17/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7536 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 18/500\n",
      "1450/1450 [==============================] - 82s 57ms/step - loss: 4.7542 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 19/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7539 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 20/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7542 - accuracy: 0.0093 - val_loss: 4.7537 - val_accuracy: 0.0059\n",
      "Epoch 21/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7537 - accuracy: 0.0093 - val_loss: 4.7537 - val_accuracy: 0.0059\n",
      "Epoch 22/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7538 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 23/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7535 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 24/500\n",
      "1450/1450 [==============================] - 81s 56ms/step - loss: 4.7535 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 25/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7535 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 26/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7534 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 27/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7536 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 28/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7534 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 29/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7537 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 30/500\n",
      "1450/1450 [==============================] - 73s 51ms/step - loss: 4.7532 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 31/500\n",
      "1450/1450 [==============================] - 74s 51ms/step - loss: 4.7537 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 32/500\n",
      "1450/1450 [==============================] - 75s 52ms/step - loss: 4.7532 - accuracy: 0.0094 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 33/500\n",
      "1450/1450 [==============================] - 75s 51ms/step - loss: 4.7532 - accuracy: 0.0093 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 34/500\n",
      "1450/1450 [==============================] - 80s 55ms/step - loss: 4.7532 - accuracy: 0.0095 - val_loss: 4.7536 - val_accuracy: 0.0059\n",
      "Epoch 35/500\n",
      " 701/1450 [=============>................] - ETA: 35s - loss: 4.7534 - accuracy: 0.0088"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}